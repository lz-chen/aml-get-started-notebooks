{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Upload, access and explore your data in Azure Machine Learning\n",
        "\n",
        "In this tutorial you learn how to:\n",
        "\n",
        "> * Upload your data to cloud storage\n",
        "> * Create an Azure Machine Learning data asset\n",
        "> * Access your data in a notebook for interactive development\n",
        "> * Create new versions of data assets\n",
        "\n",
        "The start of a machine learning project typically involves exploratory data analysis (EDA), data-preprocessing (cleaning, feature engineering), and the building of Machine Learning model prototypes to validate hypotheses. This _prototyping_ project phase is highly interactive. It lends itself to development in an IDE or a Jupyter notebook, with a _Python interactive console_. This tutorial describes these ideas.\n",
        "\n",
        "> [!NOTE]\n",
        "> This tutorial depends on data placed in an Azure Machine Learning resource folder location. For this tutorial, 'local' means a folder location in that Azure Machine Learning resource. \n",
        "\n",
        "1. Select **Open terminal** below the three dots, as shown in this image:\n",
        "\n",
        "    ![Open terminal](./media/open-terminal.png)\n",
        "\n",
        "1. The terminal window opens in a new tab. \n",
        "1. Make sure you `cd` to the same folder where this notebook is located.  For example, if the notebook is in a folder named **get-started-notebooks**:\n",
        "\n",
        "    ```\n",
        "    cd get-started-notebooks    #  modify this to the path where your notebook is located\n",
        "    ```\n",
        "\n",
        "1. Enter these commands in the terminal window to copy the data to your compute instance:\n",
        "\n",
        "    ```\n",
        "    mkdir data\n",
        "    cd data                     # the sub-folder where you'll store the data\n",
        "    wget https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default_of_credit_card_clients.csv\n",
        "    ```\n",
        "1. You can now close the terminal window.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "[Learn more about this data on the UCI Machine Learning Repository.](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)\n",
        "\n",
        "## Create handle to workspace\n",
        "\n",
        "Before we dive in the code, you need a way to reference your workspace. You'll create `ml_client` for a handle to the workspace.  You'll then use `ml_client` to manage resources and jobs.\n",
        "\n",
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
        "\n",
        "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
        "1. Copy the value for workspace, resource group and subscription ID into the code.\n",
        "1. You'll need to copy one value, close the area and paste, then come back for the next one."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
        "\n",
        "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
        "1. Copy the value for workspace, resource group and subscription ID into the code.  \n",
        "1. You'll need to copy one value, close the area and paste, then come back for the next one.\n",
        "\n",
        "![image of workspace credentials](./media/find-credentials.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from dotenv import dotenv_values\n",
        "import requests \n",
        "import os\n",
        "\n",
        "config = dotenv_values(\".env\") \n",
        "subscription_id =config['SUBSCRIPTION_ID']\n",
        "resource_group = config['RESOURCE_GP']\n",
        "workspace = config['WORKSPACE']\n",
        "\n",
        "os.environ[\"AZURE_CLIENT_ID\"] = config[\"AZURE_CLIENT_ID\"]\n",
        "os.environ[\"AZURE_CLIENT_SECRET\"] = config[\"AZURE_CLIENT_SECRET\"]\n",
        "os.environ[\"AZURE_TENANT_ID\"] = config[\"AZURE_TENANT_ID\"]\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "# Check if given credential can get token successfully.\n",
        "credential.get_token(\"https://management.azure.com/.default\")\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1686913107987
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An **Azure service principal **is a security identity used by user-created apps, services, and automation tools to access specific Azure resources. Think of it as a 'user identity' (login and password or certificate) with a specific role, and tightly controlled permissions to access your resources. It only needs to be able to do specific things, unlike a general user identity. It improves security if you only grant it the minimum permissions level needed to perform its management tasks.\n",
        "\n",
        "[How to set up authentication using Service Principle](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?view=azureml-api-2&tabs=sdk)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "> [!NOTE]\n",
        "> Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (this will happen in the next code cell)."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Upload data to cloud storage\n",
        "\n",
        "Azure Machine Learning uses Uniform Resource Identifiers (URIs), which point to storage locations in the cloud. A URI makes it easy to access data in notebooks and jobs. Data URI formats look similar to the web URLs that you use in your web browser to access web pages. For example:\n",
        "\n",
        "* Access data from public https server: `https://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>`\n",
        "* Access data from local computer:\t`./home/username/data/my_data`\n",
        "* Blob storage:\t`wasbs://<containername>@<accountname>.blob.core.windows.net/<folder>/`\n",
        "* Azure Data Lake (gen2): `abfss://<file_system>@<account_name>.dfs.core.windows.net/<folder>/<file>.csv`\n",
        "* Azure Data Lake (gen1): `adl://<accountname>.azuredatalakestore.net/<folder1>/<folder2>`\n",
        "* Azure Machine Learning Datastore:\t`azureml://datastores/<data_store_name>/paths/<folder1>/<folder2>/<folder3>/<file>.parquet`\n",
        "\n",
        "An Azure Machine Learning data asset is similar to web browser bookmarks (favorites). Instead of remembering long storage paths (URIs) that point to your most frequently used data, you can create a data asset, and then access that asset with a friendly name.\n",
        "\n",
        "Data asset creation also creates a *reference* to the data source location, along with a copy of its metadata. Because the data remains in its existing location, you incur no extra storage cost, and don't risk data source integrity. You can create Data assets from Azure Machine Learning datastores, Azure Storage, public URLs, and local files.\n",
        "\n",
        "> [!TIP]\n",
        "> For smaller-size data uploads, Azure Machine Learning data asset creation works well for data uploads from local machine resources to cloud storage. This approach avoids the need for extra tools or utilities. However, a larger-size data upload might require a dedicated tool or utility - for example, **azcopy**. The azcopy command-line tool moves data to and from Azure Storage. Learn more about [azcopy](https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10).\n",
        "\n",
        "The next notebook cell creates the data asset. The code sample uploads the raw data file to the designated cloud storage resource.  \n",
        "\n",
        "Each time you create a data asset, you need a unique version for it.  If the version already exists, you'll get an error.  In this code, we're using time to generate a unique version each time the cell is run.\n",
        "\n",
        "You can also omit the **version** parameter, and a version number is generated for you, starting with 1 and then incrementing from there. In this tutorial, we want to refer to specific version numbers, so we create a version number instead."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"./data/UCI_Credit_Card.csv\")\n",
        "df.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n       'default.payment.next.month'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1686913128334
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import time\n",
        "\n",
        "# update the 'my_path' variable to match the location of where you downloaded the data on your\n",
        "# local filesystem\n",
        "my_path = \"./data/UCI_Credit_Card.csv\"\n",
        "v1 = time.strftime(\"%Y.%m.%d.%H%M%S\", time.gmtime())\n",
        "my_data = Data(\n",
        "    name=\"credit-card\",\n",
        "    version=v1,\n",
        "    description=\"Credit card data\",\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        ")\n",
        "\n",
        "# create data asset\n",
        "ml_client.data.create_or_update(my_data)\n",
        "\n",
        "print(f\"Data asset created. Name: {my_data.name}, version: {my_data.version}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset created. Name: credit-card, version: 2023.06.16.105913\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1686913155987
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "You can see the uploaded data by selecting **Data** on the left. You'll see the data is uploaded and a data asset is created:\n",
        "\n",
        "![Image of data section of studio shows uploaded data](./media/access-and-explore-data.png)\n",
        "\n",
        "This data is named **credit-card**, and in the **Data assets** tab, we can see it in the **Name** column. This data uploaded to your workspace's default datastore named **workspaceblobstore**, seen in the **Data source** column. \n",
        "\n",
        "An Azure Machine Learning datastore is a *reference* to an *existing* storage account on Azure. A datastore offers these benefits:\n",
        "\n",
        "1. A common and easy-to-use API, to interact with different storage types (Blob/Files/Azure Data Lake Storage) and authentication methods.\n",
        "1. An easier way to discover useful datastores, when working as a team.\n",
        "1. In your scripts, a way to hide connection information for credential-based data access (service principal/SAS/key).\n",
        "\n",
        "\n",
        "## Access your data in a notebook\n",
        "\n",
        "Pandas directly support URIs - this example shows how to read a CSV file from an Azure Machine Learning Datastore:\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"azureml://subscriptions/<subid>/resourcegroups/<rgname>/workspaces/<workspace_name>/datastores/<datastore_name>/paths/<folder>/<filename>.csv\")\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "However, as mentioned previously, it can become hard to remember these URIs. Additionally, you must manually substitute all **<_substring_>** values in the **pd.read_csv** command with the real values for your resources. \n",
        "\n",
        "You'll want to create data assets for frequently accessed data. Here's an easier way to access the CSV file in Pandas:\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> In a notebook cell, execute this code to install the `azureml-fsspec` Python library in your Jupyter kernel:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# get a handle of the data asset and print the URI\n",
        "data_asset = ml_client.data.get(name=\"credit-card\", version=v1)\n",
        "print(f\"Data asset URI: {data_asset.path}\")\n",
        "\n",
        "# read into pandas - note that you will see 2 headers in your data frame - that is ok, for now\n",
        "\n",
        "df = pd.read_csv(data_asset.path)\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset URI: azureml://subscriptions/9017d57d-c4df-480d-b92d-7aea2266b0f0/resourcegroups/azure-mlops-demo/workspaces/demo-ws/datastores/workspaceblobstore/paths/LocalUpload/61c541f311e1bda7f0bb68f645ad64b7/UCI_Credit_Card.csv\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4   \n0   1    20000.0    2          2         1   24      2      2     -1     -1  \\\n1   2   120000.0    2          2         2   26     -1      2      0      0   \n2   3    90000.0    2          2         2   34      0      0      0      0   \n3   4    50000.0    2          2         1   37      0      0      0      0   \n4   5    50000.0    1          2         1   57     -1      0     -1      0   \n\n   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3   \n0  ...        0.0        0.0        0.0       0.0     689.0       0.0  \\\n1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n\n   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n0       0.0       0.0       0.0                           1  \n1    1000.0       0.0    2000.0                           1  \n2    1000.0    1000.0    5000.0                           0  \n3    1100.0    1069.0    1000.0                           0  \n4    9000.0     689.0     679.0                           0  \n\n[5 rows x 25 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_0</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>default.payment.next.month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>24</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>120000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>26</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3272.0</td>\n      <td>3455.0</td>\n      <td>3261.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>0.0</td>\n      <td>2000.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>90000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>14331.0</td>\n      <td>14948.0</td>\n      <td>15549.0</td>\n      <td>1518.0</td>\n      <td>1500.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>5000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>50000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>28314.0</td>\n      <td>28959.0</td>\n      <td>29547.0</td>\n      <td>2000.0</td>\n      <td>2019.0</td>\n      <td>1200.0</td>\n      <td>1100.0</td>\n      <td>1069.0</td>\n      <td>1000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50000.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>57</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>20940.0</td>\n      <td>19146.0</td>\n      <td>19131.0</td>\n      <td>2000.0</td>\n      <td>36681.0</td>\n      <td>10000.0</td>\n      <td>9000.0</td>\n      <td>689.0</td>\n      <td>679.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1686913244996
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download the data asset as well"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
        "\n",
        "# get a handle of the data asset and print the URI\n",
        "data = ml_client.data.get(name=\"credit-card\", version=v1)\n",
        "print(f\"Data asset URI: {data.path}\")\n",
        "\n",
        "# Download the dataset\n",
        "artifact_utils.download_artifact_from_aml_uri(uri = data.path,\n",
        "  destination = \".\",\n",
        "  datastore_operation=ml_client.datastores)\n",
        "# df = pd.read_csv(data.path)\n",
        "# df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Read [Access data from Azure cloud storage during interactive development](how-to-access-data-interactive.md) to learn more about data access in a notebook.\n",
        "\n",
        "## Create a new version of the data asset\n",
        "\n",
        "\n",
        "* a client ID column; we wouldn't use this feature in Machine Learning\n",
        "* long response variable name\n",
        "\n",
        "Also, compared to the CSV format, the Parquet file format becomes a better way to store this data. Parquet offers compression, and it maintains schema. Therefore, to clean the data and store it in Parquet, use:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in data again, this time using the 2nd row as the header\n",
        "df = pd.read_csv(data_asset.path)\n",
        "# rename column\n",
        "df.rename(columns={\"default.payment.next.month\": \"default\"}, inplace=True)\n",
        "# remove ID column\n",
        "df.drop(\"ID\", axis=1, inplace=True)\n",
        "\n",
        "# write file to filesystem\n",
        "df.to_parquet(\"./data/cleaned-credit-card.parquet\")"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1686913254974
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "This table shows the structure of the data in the original **default_of_credit_card_clients.csv** file .CSV file downloaded in an earlier step. The uploaded data contains 23 explanatory variables and 1 response variable, as shown here:\n",
        "\n",
        "|Column Name(s) | Variable Type  |Description  |\n",
        "|---------|---------|---------|\n",
        "|X1     |   Explanatory      |    Amount of the given credit (NT dollar): it includes both the individual consumer credit and their family (supplementary) credit.    |\n",
        "|X2     |   Explanatory      |   Gender (1 = male; 2 = female).      |\n",
        "|X3     |   Explanatory      |   Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).      |\n",
        "|X4     |   Explanatory      |    Marital status (1 = married; 2 = single; 3 = others).     |\n",
        "|X5     |   Explanatory      |    Age (years).     |\n",
        "|X6-X11     | Explanatory        |  History of past payment. We tracked the past monthly payment records (from April to September  2005). -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.      |\n",
        "|X12-17     | Explanatory        |  Amount of bill statement (NT dollar) from April to September  2005.      |\n",
        "|X18-23     | Explanatory        |  Amount of previous payment (NT dollar) from April to September  2005.      |\n",
        "|Y     | Response        |    Default payment (Yes = 1, No = 0)     |\n",
        "\n",
        "Next, create a new _version_ of the data asset (the data automatically uploads to cloud storage):\n",
        "\n",
        "> [!NOTE]\n",
        ">\n",
        "> This Python code cell sets **name** and **version** values for the data asset it creates. As a result, the code in this cell will fail if executed more than once, without a change to these values. Fixed **name** and **version** values offer a way to pass values that work for specific situations, without concern for auto-generated or randomly-generated values.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import time\n",
        "\n",
        "# Next, create a new *version* of the data asset (the data is automatically uploaded to cloud storage):\n",
        "my_path = \"./data/cleaned-credit-card.parquet\"\n",
        "v2 = time.strftime(\"%Y.%m.%d.%H%M%S\", time.gmtime())\n",
        "# Define the data asset, and use tags to make it clear the asset can be used in training\n",
        "\n",
        "my_data = Data(\n",
        "    name=\"credit-card\",\n",
        "    version=v2,\n",
        "    description=\"Default of credit card clients data.\",\n",
        "    tags={\"training_data\": \"true\", \"format\": \"parquet\"},\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        ")\n",
        "\n",
        "## create the data asset\n",
        "\n",
        "my_data = ml_client.data.create_or_update(my_data)\n",
        "\n",
        "print(f\"Data asset created. Name: {my_data.name}, version: {my_data.version}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset created. Name: credit-card, version: 2023.06.16.110114\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1686913275295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The cleaned parquet file is the latest version data source. This code shows the CSV version result set first, then the Parquet version:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# get a handle of the data asset and print the URI\n",
        "data_asset_v1 = ml_client.data.get(name=\"credit-card\", version=v1)\n",
        "data_asset_v2 = ml_client.data.get(name=\"credit-card\", version=v2)\n",
        "\n",
        "# print the v1 data\n",
        "print(f\"V1 Data asset URI: {data_asset_v1.path}\")\n",
        "v1df = pd.read_csv(data_asset_v1.path)\n",
        "print(v1df.head(5))\n",
        "\n",
        "# print the v2 data\n",
        "print(\n",
        "    \"_____________________________________________________________________________________________________________\\n\"\n",
        ")\n",
        "print(f\"V2 Data asset URI: {data_asset_v2.path}\")\n",
        "v2df = pd.read_parquet(data_asset_v2.path)\n",
        "print(v2df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "V1 Data asset URI: azureml://subscriptions/9017d57d-c4df-480d-b92d-7aea2266b0f0/resourcegroups/azure-mlops-demo/workspaces/demo-ws/datastores/workspaceblobstore/paths/LocalUpload/61c541f311e1bda7f0bb68f645ad64b7/UCI_Credit_Card.csv\n   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4   \n0   1    20000.0    2          2         1   24      2      2     -1     -1  \\\n1   2   120000.0    2          2         2   26     -1      2      0      0   \n2   3    90000.0    2          2         2   34      0      0      0      0   \n3   4    50000.0    2          2         1   37      0      0      0      0   \n4   5    50000.0    1          2         1   57     -1      0     -1      0   \n\n   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3   \n0  ...        0.0        0.0        0.0       0.0     689.0       0.0  \\\n1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n\n   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n0       0.0       0.0       0.0                           1  \n1    1000.0       0.0    2000.0                           1  \n2    1000.0    1000.0    5000.0                           0  \n3    1100.0    1069.0    1000.0                           0  \n4    9000.0     689.0     679.0                           0  \n\n[5 rows x 25 columns]\n_____________________________________________________________________________________________________________\n\nV2 Data asset URI: azureml://subscriptions/9017d57d-c4df-480d-b92d-7aea2266b0f0/resourcegroups/azure-mlops-demo/workspaces/demo-ws/datastores/workspaceblobstore/paths/LocalUpload/fd2381a3089649ee70489931960c523a/cleaned-credit-card.parquet\n   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4   \n0    20000.0    2          2         1   24      2      2     -1     -1  \\\n1   120000.0    2          2         2   26     -1      2      0      0   \n2    90000.0    2          2         2   34      0      0      0      0   \n3    50000.0    2          2         1   37      0      0      0      0   \n4    50000.0    1          2         1   57     -1      0     -1      0   \n\n   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3   \n0     -2  ...        0.0        0.0        0.0       0.0     689.0       0.0  \\\n1      0  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n2      0  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n3      0  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n4      0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n\n   PAY_AMT4  PAY_AMT5  PAY_AMT6  default  \n0       0.0       0.0       0.0        1  \n1    1000.0       0.0    2000.0        1  \n2    1000.0    1000.0    5000.0        0  \n3    1100.0    1069.0    1000.0        0  \n4    9000.0     689.0     679.0        0  \n\n[5 rows x 24 columns]\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1686913325986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "description": {
      "description": "Upload data to cloud storage, create a data asset, create new versions for data assets, use the data for interactive development."
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}