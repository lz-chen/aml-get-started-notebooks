{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Train a model\n",
        "\n",
        "Learn how a data scientist uses Azure Machine Learning to train a model.  In this example, we use the associated credit card dataset to show how you can use Azure Machine Learning for a classification problem. The goal is to predict if a customer has a high likelihood of defaulting on a credit card payment.\n",
        "\n",
        "The training script handles the data preparation, then trains and registers a model. This tutorial takes you through steps to submit a cloud-based training job (command job). If you would like to learn more about how to load your data into Azure, see [Create data assets](how-to-create-data-assets.md). \n",
        "\n",
        "The steps are:\n",
        "\n",
        " * Get a handle to your Azure Machine Learning workspace\n",
        " * Create your compute resource and job environment\n",
        " * Create your training script\n",
        " * Create and run your command job to run the training script on the compute resource, configured with the appropriate job environment and the data source\n",
        " * View the output of your training script\n",
        " * Deploy the newly-trained model as an endpoint\n",
        " * Call the Azure Machine Learning endpoint for inferencing"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "* If you opened this notebook from Azure Machine Learning studio, you need a compute instance to run the code. If you don't have a compute instance, select **Create compute** on the toolbar to first create one.  You can use all the default settings.  \n",
        "\n",
        "    ![Create compute](./media/create-compute.png)\n",
        "\n",
        "* If you're seeing this notebook elsewhere, complete [Create resources you need to get started](https://docs.microsoft.com/azure/machine-learning/quickstart-create-resources) to create an Azure Machine Learning workspace and a compute instance.\n",
        "\n",
        "## Set your kernel\n",
        "\n",
        "* If your compute instance is stopped, start it now.  \n",
        "        \n",
        "    ![Start compute](./media/start-compute.png)\n",
        "\n",
        "* Once your compute instance is running, make sure the that the kernel, found on the top right, is `Python 3.10 - SDK v2`.  If not, use the dropdown to select this kernel.\n",
        "\n",
        "    ![Set the kernel](./media/set-kernel.png)"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Use a command job to train a model in Azure Machine Learning\n",
        "\n",
        "To train a model, you need to submit a *job*. The type of job you'll submit in this tutorial is a *command job*. Azure Machine Learning offers several different types of jobs to train models. Users can select their method of training based on complexity of the model, data size, and training speed requirements.  In this tutorial, you'll learn how to submit a *command job* to run a *training script*. \n",
        "\n",
        "A command job is a function that allows you to submit a custom training script to train your model. This can also be defined as a custom training job. A command job in Azure Machine Learning is a type of job that runs a script or command in a specified environment. You can use command jobs to train models, process data, or any other custom code you want to execute in the cloud. \n",
        "\n",
        "In this tutorial, we'll focus on using a command job to create a custom training job that we'll use to train a model. For any custom training job, the below items are required:\n",
        "\n",
        "* compute resource (usually a compute cluster, which we recommend for scalability)\n",
        "* environment\n",
        "* data\n",
        "* command job \n",
        "* training script\n",
        "\n",
        "\n",
        "In this tutorial we'll provide all these items for our example: creating a classifier to predict customers who have a high likelihood of defaulting on credit card payments.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create handle to workspace\n",
        "\n",
        "Before we dive in the code, you need a way to reference your workspace. You'll create `ml_client` for a handle to the workspace.  You'll then use `ml_client` to manage resources and jobs.\n",
        "\n",
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
        "\n",
        "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
        "1. Copy the value for workspace, resource group and subscription ID into the code.\n",
        "1. You'll need to copy one value, close the area and paste, then come back for the next one."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from dotenv import dotenv_values\n",
        "import requests \n",
        "import os\n",
        "\n",
        "config = dotenv_values(\".env\") \n",
        "subscription_id =config['SUBSCRIPTION_ID']\n",
        "resource_group = config['RESOURCE_GP']\n",
        "workspace = config['WORKSPACE']\n",
        "\n",
        "os.environ[\"AZURE_CLIENT_ID\"] = config[\"AZURE_CLIENT_ID\"]\n",
        "os.environ[\"AZURE_CLIENT_SECRET\"] = config[\"AZURE_CLIENT_SECRET\"]\n",
        "os.environ[\"AZURE_TENANT_ID\"] = config[\"AZURE_TENANT_ID\"]\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "# Check if given credential can get token successfully.\n",
        "credential.get_token(\"https://management.azure.com/.default\")\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1686825192038
        },
        "name": "credential"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "> [!NOTE]\n",
        "> Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (this will happen in the next code cell)."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a compute cluster to run your job\n",
        "\n",
        "In Azure, a job can refer to several tasks that Azure allows its users to do: training, pipeline creation, deployment, etc. For this tutorial and our purpose of training a machine learning model, we'll use *job* as a reference to running training computations (*training job*).\n",
        "\n",
        "You need a compute resource for running any job in Azure Machine Learning. It can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark. In Azure, there are two compute resources that you can choose from: instance and cluster. A compute instance contains one node of computation resources while a *compute cluster* contains several. A *compute cluster* contains more memory for the computation task. For training, we recommend using a compute cluster because it allows the user to distribute calculations on multiple nodes of computation, which results in a faster training experience. \n",
        "\n",
        "You provision a Linux compute cluster. See the [full list on VM sizes and prices](https://azure.microsoft.com/pricing/details/machine-learning/) .\n",
        "\n",
        "For this example, you only need a basic cluster, so you use a Standard_DS3_v2 model with 2 vCPU cores, 7-GB RAM."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure Machine Learning compute object with the intended parameters\n",
        "    # if you run into an out of quota error, change the size to a comparable VM that is available.\n",
        "    # Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure Machine Learning Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=4,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "    print(\n",
        "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
        "    )\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You already have a cluster named cpu-cluster, we'll reuse it as is.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1686825199536
        },
        "name": "cpu_compute_target"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a job environment\n",
        "\n",
        "To run your Azure Machine Learning job on your compute resource, you need an [environment](https://learn.microsoft.com/articles/machine-learning/concept-environments). An environment lists the software runtime and libraries that you want installed on the compute where you’ll be training. It's similar to your python environment on your local machine.\n",
        "\n",
        "Azure Machine Learning provides many curated or ready-made environments, which are useful for common training and inference scenarios. \n",
        "\n",
        "In this example, you'll create a custom conda environment for your jobs, using a conda yaml file.\n",
        "\n",
        "First, create a directory to store the file in."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "dependencies_dir = \"./dependencies\"\n",
        "custom_env_name = \"aml-scikit-learn\"\n",
        "\n",
        "custom_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Credit Card Defaults job\",\n",
        "    tags={\"scikit-learn\": \"0.24.2\"},\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
        ")\n",
        "custom_job_env = ml_client.environments.create_or_update(custom_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {custom_job_env.name} is registered to workspace, the environment version is {custom_job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name aml-scikit-learn is registered to workspace, the environment version is 2\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1686825205538
        },
        "name": "custom_env_name"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Configure a training job using the command function\n",
        "\n",
        "You create an Azure Machine Learning *command job* to train a model for credit default prediction. The command job runs a *training script* in a specified environment on a specified compute resource.  You've already created the environment and the compute cluster.  Next you'll create the training script. In our specific case, we're training our dataset to produce a classifier using the `GradientBoostingClassifier` model. \n",
        "\n",
        "The *training script* handles the data preparation, training and registering of the trained model. The method `train_test_split` handles splitting the dataset into test and training data. In this tutorial, you'll create a Python training script. \n",
        "\n",
        "Command jobs can be run from CLI, Python SDK, or studio interface. In this tutorial, you'll use the Azure Machine Learning Python SDK v2 to create and run the command job.\n",
        "\n",
        "## Create training script\n",
        "\n",
        "Let's start by creating the training script - the *main.py* python file.\n",
        "\n",
        "First create a source folder for the script:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1686825213269
        },
        "name": "train_src_dir"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "This script handles the preprocessing of the data, splitting it into test and train data. It then consumes this data to train a tree based model and return the output model. \n",
        "\n",
        "[MLFlow](https://learn.microsoft.com/articles/machine-learning/concept-mlflow) is used to log the parameters and metrics during our job. The MLFlow package allows you to keep track of metrics and results for each model Azure trains. We'll be using MLFlow to first get the best model for our data, then we'll view the model's metrics on the Azure studio. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    ###################\n",
        "    #<prepare the data>\n",
        "    ###################\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.data)\n",
        "    \n",
        "    credit_df = pd.read_parquet(args.data, header=1, index_col=0)\n",
        "\n",
        "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
        "\n",
        "    #Split train and test datasets\n",
        "    train_df, test_df = train_test_split(\n",
        "        credit_df,\n",
        "        test_size=args.test_train_ratio,\n",
        "    )\n",
        "    ####################\n",
        "    #</prepare the data>\n",
        "    ####################\n",
        "\n",
        "    ##################\n",
        "    #<train the model>\n",
        "    ##################\n",
        "    # Extracting the label column\n",
        "    y_train = train_df.pop(\"default payment next month\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_train = train_df.values\n",
        "\n",
        "    # Extracting the label column\n",
        "    y_test = test_df.pop(\"default payment next month\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_test = test_df.values\n",
        "\n",
        "    print(f\"Training with data of shape {X_train.shape}\")\n",
        "\n",
        "    clf = GradientBoostingClassifier(\n",
        "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    ###################\n",
        "    #</train the model>\n",
        "    ###################\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=clf,\n",
        "        registered_model_name=args.registered_model_name,\n",
        "        artifact_path=args.registered_model_name,\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=clf,\n",
        "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "    \n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing ./src/main.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "name": "write_main"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "In this script, once the model is trained, the model file is saved and registered to the workspace. Registering your model allows you to store and version your models in the Azure cloud, in your workspace. Once you register a model, you can find all other registered model in one place in the Azure Studio called the model registry. The model registry helps you organize and keep track of your trained models. \n",
        "\n",
        "## Configure the command\n",
        "\n",
        "Now that you have a script that can perform the classification task, use the general purpose **command** that can run command line actions. This command line action can be directly calling system commands or by running a script. \n",
        "\n",
        "Here, create input variables to specify the input data, split ratio, learning rate and registered model name.  The command script will:\n",
        "* Use the compute created earlier to run this command.\n",
        "* Use the environment created earlier - you can use the `@latest` notation to indicate the latest version of the environment when the command is run.\n",
        "* Configure the command line action itself - `python main.py` in this case. The inputs/outputs are accessible in the command via the `${{ ... }}` notation."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "registered_model_name = \"credit_defaults_model\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"https://azuremlexamples.blob.core.windows.net/datasets/credit-card/default_credit_card.parquet\",\n",
        "        ),\n",
        "        test_train_ratio=0.2,\n",
        "        learning_rate=0.25,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"aml-scikit-learn@latest\",\n",
        "    compute=\"cpu-cluster\",\n",
        "    display_name=\"credit_default_prediction\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1686825687487
        },
        "name": "registered_model_name"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Submit the job \n",
        "\n",
        "It's now time to submit the job to run in Azure Machine Learning studio. This time you'll use `create_or_update`  on `ml_client`. `ml_client` is a client class that allows you to connect to your Azure subscription using Python and interact with Azure Machine Learning services. `ml_client` allows you to submit your jobs using Python."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "Command({'parameters': {}, 'init': False, 'type': 'command', 'status': 'Starting', 'log_files': None, 'name': 'bubbly_library_mxhgdv2gbw', 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '83ed23e7-fc87-4f2d-abd4-f82ccdd22d45'}, 'print_as_yaml': True, 'id': '/subscriptions/9017d57d-c4df-480d-b92d-7aea2266b0f0/resourceGroups/azure-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/demo-ws/jobs/bubbly_library_mxhgdv2gbw', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/lc-cpu/code/Users/lingzhen.chen/workshop-demo/get-started-notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8c4e33b520>, 'serialize': <msrest.serialization.Serializer object at 0x7f8c4e33bca0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'credit_default_prediction', 'experiment_name': 'get-started-notebooks', 'compute': 'cpu-cluster', 'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f8c729b37f0>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f8c4e33bd60>}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'https://azuremlexamples.blob.core.windows.net/datasets/credit-card/default_credit_card.parquet', 'mode': 'ro_mount'}, 'test_train_ratio': '0.2', 'learning_rate': '0.25', 'registered_model_name': 'credit_defaults_model'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.bubbly_library_mxhgdv2gbw', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8c4e33b4f0>, 'test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8c4e398790>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8c4e3985b0>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8c4e398850>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f8c4e398130>}, 'component': CommandComponent({'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'name': 'bubbly_library_mxhgdv2gbw', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8c4e33b520>, 'serialize': <msrest.serialization.Serializer object at 0x7f8c4e33bdc0>, 'command': 'python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}', 'code': '/subscriptions/9017d57d-c4df-480d-b92d-7aea2266b0f0/resourceGroups/azure-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/demo-ws/codes/3423e5bc-4a5e-4d83-b20a-285fa77b1765/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/9017d57d-c4df-480d-b92d-7aea2266b0f0/resourceGroups/azure-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/demo-ws/environments/aml-scikit-learn/versions/2', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'credit_default_prediction', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'https://azuremlexamples.blob.core.windows.net/datasets/credit-card/default_credit_card.parquet', 'mode': 'ro_mount'}, 'test_train_ratio': {'type': 'string', 'default': '0.2'}, 'learning_rate': {'type': 'string', 'default': '0.25'}, 'registered_model_name': {'type': 'string', 'default': 'credit_defaults_model'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.bubbly_library_mxhgdv2gbw', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f8c729b37f0>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7f8c4e33bd60>}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8c4e33b520>}, 'instance_id': '6090b7ce-d458-4441-a080-7c5e4def6396', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'aml-scikit-learn:2', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>get-started-notebooks</td><td>bubbly_library_mxhgdv2gbw</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/bubbly_library_mxhgdv2gbw?wsid=/subscriptions/9017d57d-c4df-480d-b92d-7aea2266b0f0/resourcegroups/azure-mlops-demo/workspaces/demo-ws&amp;tid=8f47ad71-44ca-48bf-afe3-56b9360a4495\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1686825693498
        },
        "name": "create_job"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## View job output and wait for job completion\n",
        "\n",
        "View the job in Azure Machine Learning studio by selecting the link in the output of the previous cell. The output of this job will look like this in the Azure Machine Learning studio. Explore the tabs for various details like metrics, outputs etc. Once completed, the job will register a model in your workspace as a result of training. \n",
        "\n",
        "![Screenshot shows the overview page for the job.](./media/view-job.gif)\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> Wait until the status of the job is complete before returning to this notebook to continue. The job will take 2 to 3 minutes to run. It could take longer (up to 10 minutes) if the compute cluster has been scaled down to zero nodes and custom environment is still building.\n",
        "\n",
        "When you run the cell, the notebook output shows a link to the job's details page on Azure Studio. Alternatively, you can also select Jobs on the left navigation menu. A job is a grouping of many runs from a specified script or piece of code. Information for the run is stored under that job. The details page gives an overview of the job, the time it took to run, when it was created, etc. The page also has tabs to other information about the job such as metrics, Outputs + logs, and code. Listed below are the tabs available in the job's details page:\n",
        "\n",
        "* Overview: The overview section provides basic information about the job, including its status, start and end times, and the type of job that was run\n",
        "* Inputs: The input section lists the data and code that were used as inputs for the job. This section can include datasets, scripts, environment configurations, and other resources that were used during training. \n",
        "* Outputs + logs: The Outputs + logs tab contains logs generated while the job was running. This tab assists in troubleshooting if anything goes wrong with your training script or model creation.\n",
        "* Metrics: The metrics tab showcases key performance metrics from your model such as training score, f1 score, and precision score. "
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Clean up resources\n",
        "\n",
        "If you plan to continue now to other tutorials, skip to [Next steps](#next-steps).\n",
        "\n",
        "### Stop compute instance\n",
        "\n",
        "If you're not going to use it now, stop the compute instance:\n",
        "\n",
        "1. In the studio, in the left navigation area, select **Compute**.\n",
        "1. In the top tabs, select **Compute instances**\n",
        "1. Select the compute instance in the list.\n",
        "1. On the top toolbar, select **Stop**.\n"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "Learn about deploying a model \n",
        "\n",
        "[Deploy a model](https://learn.microsoft.com/articles/machine-learning/tutorial-deploy-model).\n",
        "\n",
        "This tutorial used an online data file.  To learn more about other ways to access data, see [Tutorial: Upload, access and explore your data in Azure Machine Learning](https://learn.microsoft.com/articles/machine-learning/tutorial-explore-data).\n",
        "\n",
        "If you would like to learn more about different ways to train models in Azure Machine Learning, see [What is automated machine learning (AutoML)?](https://learn.microsoft.com/articles/machine-learning/concept-automated-ml). Automated ML is a supplemental tool to reduce the amount of time a data scientist spends finding a model that works best with their data.\n",
        "\n",
        "If you would like more examples similar to this tutorial, see [**Samples**](https://learn.microsoft.com/articles/machine-learning/quickstart-create-resources#learn-from-sample-notebooks) section of studio. These same samples are available at our [GitHub examples page.](https://github.com/Azure/azureml-examples) The examples include complete Python Notebooks that you can run code and learn to train a model. You can modify and run  existing scripts from the samples, containing scenarios including classification, natural language processing, and anomaly detection. \n",
        "\n",
        "To train models by creating your own custom environments using a [docker image,](how-to-manage-environments-v2.md#create-an-environment-from-a-docker-build-context)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "categories": [
      "SDK v2",
      "tutorials"
    ],
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}